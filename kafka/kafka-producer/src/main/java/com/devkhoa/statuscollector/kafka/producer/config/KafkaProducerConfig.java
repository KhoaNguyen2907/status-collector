package com.devkhoa.statuscollector.kafka.producer.config;

import com.devkhoa.statuscollector.configdata.KafkaConfigData;
import com.devkhoa.statuscollector.configdata.KafkaProducerConfigData;
import org.apache.avro.specific.SpecificRecordBase;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.io.Serializable;
import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig<K extends Serializable, V extends SpecificRecordBase> {
    private final KafkaConfigData kafkaConfigData;
    private final KafkaProducerConfigData kafkaProducerConfigData;

    public KafkaProducerConfig(KafkaConfigData kafkaConfigData, KafkaProducerConfigData kafkaProducerConfigData) {
        this.kafkaConfigData = kafkaConfigData;
        this.kafkaProducerConfigData = kafkaProducerConfigData;
    }

    @Bean
    public Map<String, Object> producerConfig() {
        Map<String, Object> props = new HashMap<>();
        // BOOTSTRAP_SERVERS_CONFIG: This is the list of host:port pairs used for establishing the initial connection to the Kafka cluster.
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConfigData.getBootstrapServers());
        // The URL of the schema registry. The schema registry is a server that runs in the Kafka cluster and provides a RESTful interface to pre-define schemas which are then available via both RESTful interface and a native Kafka client.
        props.put(kafkaConfigData.getSchemaRegistryUrlKey(), kafkaConfigData.getSchemaRegistryUrl());
        // KEY_SERIALIZER_CLASS_CONFIG: This is the serializer class for keys. This class should implement the `org.apache.kafka.common.serialization.Serializer` interface.
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, kafkaProducerConfigData.getKeySerializerClass());
        // VALUE_SERIALIZER_CLASS_CONFIG: This is the serializer class for values. This class should implement the `org.apache.kafka.common.serialization.Serializer` interface.
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, kafkaProducerConfigData.getValueSerializerClass());
        // BATCH_SIZE_CONFIG: This is the batch size in bytes. When multiple records are sent to the same partition, the producer will batch them together. This property specifies the batch size in bytes.
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, kafkaProducerConfigData.getBatchSize() *
                kafkaProducerConfigData.getBatchSizeBoostFactor());
        // LINGER_MS_CONFIG: This is the delay in milliseconds that the producer will wait in hope of more records arriving. This can reduce the number of requests made, but at the cost of adding some latency.
        props.put(ProducerConfig.LINGER_MS_CONFIG, kafkaProducerConfigData.getLingerMs());
        // COMPRESSION_TYPE_CONFIG: This is the compression type for all data generated by the producer. The allowed values are 'none', 'gzip', 'snappy', or 'lz4'. Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio.
        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, kafkaProducerConfigData.getCompressionType());
        // ACKS_CONFIG: This is the number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent.
        props.put(ProducerConfig.ACKS_CONFIG, kafkaProducerConfigData.getAcks());
        // REQUEST_TIMEOUT_MS_CONFIG: This is the configuration for the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, kafkaProducerConfigData.getRequestTimeoutMs());
        // RETRIES_CONFIG: This property will cause the producer to automatically retry a failed send request. This property specifies the number of retries when such failures occur. Note that setting a value greater than zero will cause failed sends to be retried.
        props.put(ProducerConfig.RETRIES_CONFIG, kafkaProducerConfigData.getRetryCount());
        return props;
    }

    @Bean
    public ProducerFactory<K, V> producerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfig());
    }

    @Bean
    public KafkaTemplate<K, V> kafkaTemplate()  {
        return new KafkaTemplate<>(producerFactory());
    }


}
